{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNZUZlHHa+I4OBnrf5iIjBi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium"},"cells":[{"cell_type":"markdown","source":["# Evaluate PromCSE"],"metadata":{"id":"2qQk3GjdXLi0"}},{"cell_type":"markdown","source":["# Installation"],"metadata":{"id":"QYJqKctstgVc"}},{"cell_type":"code","source":["!pip install transformers==4.2.1"],"metadata":{"id":"wVZeIGjshDle"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"pZJDOL9gtcMs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Import Libraries"],"metadata":{"id":"tDDZ4hb7teSJ"}},{"cell_type":"code","source":["import sys\n","import io, os\n","import numpy as np\n","import logging\n","import argparse\n","from prettytable import PrettyTable\n","import torch\n","import transformers\n","from transformers import AutoConfig, AutoTokenizer\n"],"metadata":{"id":"9GILuCaxtcPP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from dataclasses import dataclass, field\n","from typing import Optional, Union, List, Dict, Tuple"],"metadata":{"id":"Y00rbFmztcRz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import (\n","    CONFIG_MAPPING,\n","    MODEL_FOR_MASKED_LM_MAPPING,\n","    AutoConfig,\n","    AutoModelForMaskedLM,\n","    AutoModelForSequenceClassification,\n","    AutoTokenizer,\n","    DataCollatorForLanguageModeling,\n","    DataCollatorWithPadding,\n","    HfArgumentParser,\n","    Trainer,\n","    TrainingArguments,\n","    default_data_collator,\n","    set_seed,\n","    EvalPrediction,\n","    BertModel,\n","    BertForPreTraining,\n","    RobertaModel\n",")"],"metadata":{"id":"xKDVWdwyRG5g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Configuration"],"metadata":{"id":"EyQlwQfxtkSK"}},{"cell_type":"code","source":["# Set up logger\n","logging.basicConfig(format='%(asctime)s : %(message)s')\n","logger = logging.getLogger()\n","logger.setLevel(logging.DEBUG)"],"metadata":{"id":"GRoCEfMp-RyS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"id":"Pr2pld5KC6co"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["PROJECT_DIR = \"/content/drive/MyDrive/patent\""],"metadata":{"id":"mKpLsxhPtuuq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["DATA_DIR = PROJECT_DIR + '/data'"],"metadata":{"id":"M0AjK3xFDCfl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import sys\n","import os\n","py_file_location = PROJECT_DIR + \"/py_files\"\n","sys.path.append(os.path.abspath(py_file_location))"],"metadata":{"id":"RH4NZy0oDQuz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from promcse.models import RobertaForCL, BertForCL"],"metadata":{"id":"A31Q5dAJDRDz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import senteval"],"metadata":{"id":"3w1yh5to-R2_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from senteval.tools.relatedness import RelatednessPytorch\n","from senteval.tools.validation import SplitClassifier\n","from senteval import utils"],"metadata":{"id":"tELdpLGA66ai"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","from senteval.binary import CREval, MREval, MPQAEval, SUBJEval\n","from senteval.snli import SNLIEval\n","from senteval.trec import TRECEval\n","from senteval.sick import SICKEntailmentEval, SICKEval\n","from senteval.mrpc import MRPCEval\n","from senteval.sts import STS12Eval, STS13Eval, STS14Eval, STS15Eval, STS16Eval, STSBenchmarkEval, SICKRelatednessEval, STSBenchmarkFinetune, STSEval\n","from senteval.sst import SSTEval\n","from senteval.rank import ImageCaptionRetrievalEval\n","from senteval.probing import *"],"metadata":{"id":"0iWNHVQf7Bcd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from senteval.utils import cosine"],"metadata":{"id":"8LlpMTpWKyO2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def print_table(task_names, scores):\n","    tb = PrettyTable()\n","    tb.field_names = task_names\n","    tb.add_row(scores)\n","    print(tb)"],"metadata":{"id":"vty5MAZJ-R54"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["MODEL_NAME = 'bert-base-uncased'\n","#MODEL_NAME = 'roberta-large'\n","#OUTPUT_NAME = 'nli_' + MODEL_NAME + '_sup-dcpcse'\n","OUTPUT_NAME = 'patent_' + MODEL_NAME + '_sup-dcpcse'\n"],"metadata":{"id":"njicqbBqFHPL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["CACHE_DIR = DATA_DIR + '/cache'"],"metadata":{"id":"Ia1wcZvmFHR9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sent0_col = 1\n","sent1_col = 2\n","score_col = 4"],"metadata":{"id":"Z-sOLhEAF4RJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"iRdprFOnzui8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@dataclass\n","class ModelArguments:\n","    model_name_or_path: Optional[str] = field(\n","        default=DATA_DIR + '/results/' + OUTPUT_NAME,\n","        metadata={\n","            \"help\": \"The model checkpoint for weights initialization.\"\n","        }\n","    )\n","    pooler_type: str = field(\n","        default=\"cls\",\n","        metadata={\n","            \"help\": \"What kind of pooler to use (cls, cls_before_pooler, avg, avg_top2, avg_first_last).\"\n","        }\n","    ) \n","    temp: float = field(\n","        default=0.05,\n","        metadata={\n","            \"help\": \"Temperature for softmax.\"\n","        }\n","    )\n","    hard_negative_weight: float = field(\n","        default=0.0,\n","        metadata={\n","            \"help\": \"The **logit** of weight for hard negatives (only effective if hard negatives are used).\"\n","        }\n","    )\n","    do_mlm: bool = field(\n","        default=False,\n","        metadata={\n","            \"help\": \"Whether to use MLM auxiliary objective.\"\n","        }\n","    )\n","    mlm_weight: float = field(\n","        default=0.1,\n","        metadata={\n","            \"help\": \"Weight for MLM auxiliary objective (only effective if --do_mlm).\"\n","        }\n","    )\n","    mlp_only_train: bool = field(\n","        default=False,\n","        metadata={\n","            \"help\": \"Use MLP only during training\"\n","        }\n","    )\n","    # Added - Begin\n","    pre_seq_len: int = field(\n","        default=10,\n","        metadata={\n","            \"help\": \"The length of prompt\"\n","        }\n","    )\n","    prefix_projection: bool = field(\n","        default=False,\n","        metadata={\n","            \"help\": \"Apply a two-layer MLP head over the prefix embeddings\"\n","        }\n","    ) \n","    prefix_hidden_size: int = field(\n","        default=512,\n","        metadata={\n","            \"help\": \"The hidden size of the MLP projection head in Prefix Encoder if prefix projection is used\"\n","        }\n","    )\n","    do_eh_loss: bool = field(\n","        default=False,\n","        metadata={\n","            \"help\": \"Whether to add Energy-based Hinge loss\"\n","        }\n","    )\n","    eh_loss_margin: float = field(\n","        default=None,\n","        metadata={\n","            \"help\": \"The margin of Energy-based Hinge loss\"\n","        }\n","    )\n","    eh_loss_weight: float = field(\n","        default=None,\n","        metadata={\n","            \"help\": \"The weight of Energy-based Hinge loss\"\n","        }\n","    )\n","\n","    cache_dir: Optional[str] = field(\n","        default=CACHE_DIR,\n","        metadata={\"help\": \"Where do you want to store the pretrained models downloaded from huggingface.co\"},\n","    )\n","    model_revision: str = field(\n","        default=\"main\",\n","        metadata={\"help\": \"The specific model version to use (can be a branch name, tag name or commit id).\"},\n","    )\n","    use_auth_token: bool = field(\n","        default=False,\n","        metadata={\n","            \"help\": \"Will use the token generated when running `transformers-cli login` (necessary to use this script \"\n","            \"with private models).\"\n","        },\n","    )\n","    mode: str = field(\n","        default=\"test\",\n","        metadata={\"help\": \"The specific model version to use (can be a branch name, tag name or commit id).\"},\n","    )\n","    task_set: str = field(\n","        default=\"sts\",\n","        metadata={\"help\": \"The specific model version to use (can be a branch name, tag name or commit id).\"},\n","    )\n"],"metadata":{"id":"GXRQ5IgtF6w2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tasks = ['PatentEval', 'STS12', 'STS13', 'STS14', 'STS15', 'STS16',\n","                     'MR', 'CR', 'MPQA', 'SUBJ', 'SST2', 'TREC', 'MRPC',\n","                     'SICKRelatedness', 'STSBenchmark']"],"metadata":{"id":"kM2HNUTlj7lk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"SEh6wPvZ-R76"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["parser = HfArgumentParser((ModelArguments))"],"metadata":{"id":"S8tY5Xxtd3Nd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["args, = parser.parse_args_into_dataclasses(args=[])\n","args"],"metadata":{"id":"iG11-8nMd_uL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls /content/drive/MyDrive/patent/data/results/nli_bert-base-uncased_sup-dcpcse"],"metadata":{"id":"KoVRIDWxku8o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["config = AutoConfig.from_pretrained(args.model_name_or_path)"],"metadata":{"id":"Ja6ytOrU-R-S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"TI2MQEZFTd1O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if 'roberta' in args.model_name_or_path:\n","    model = RobertaForCL.from_pretrained(\n","            args.model_name_or_path,\n","            from_tf=bool(\".ckpt\" in args.model_name_or_path),\n","            config=config,\n","            cache_dir=args.cache_dir,\n","            revision=args.model_revision,\n","            use_auth_token=True if args.use_auth_token else None,\n","            model_args=args                  \n","        )\n","elif 'bert' in args.model_name_or_path:\n","    model = BertForCL.from_pretrained(\n","            args.model_name_or_path,\n","            from_tf=bool(\".ckpt\" in args.model_name_or_path),\n","            config=config,\n","            cache_dir=args.cache_dir,\n","            revision=args.model_revision,\n","            use_auth_token=True if args.use_auth_token else None,\n","            model_args=args\n","        )\n"],"metadata":{"id":"c4deVPE_-SA7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(args.model_name_or_path)"],"metadata":{"id":"oi2LoU1F-SEx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)"],"metadata":{"id":"6aHfQyytCVDU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set up the tasks\n","if args.task_set == 'sts':\n","    args.tasks = ['PatentEval', 'STS12', 'STS13', 'STS14', 'STS15', 'STS16', 'STSBenchmark', 'SICKRelatedness']\n","elif args.task_set == 'transfer':\n","    args.tasks = ['MR', 'CR', 'MPQA', 'SUBJ', 'SST2', 'TREC', 'MRPC']\n","elif args.task_set == 'full':\n","    args.tasks = ['STS12', 'STS13', 'STS14', 'STS15', 'STS16', 'STSBenchmark', 'SICKRelatedness']\n","    args.tasks += ['MR', 'CR', 'MPQA', 'SUBJ', 'SST2', 'TREC', 'MRPC']\n"],"metadata":{"id":"ahY50YmICVGG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set params for SentEval\n","if args.mode == 'dev' or args.mode == 'fasttest':\n","    # Fast mode\n","    params = {'task_path': DATA_DIR, 'usepytorch': True, 'kfold': 5}\n","    params['classifier'] = {'nhid': 0, 'optim': 'rmsprop', 'batch_size': 128,\n","                                      'tenacity': 3, 'epoch_size': 2}\n","elif args.mode == 'test':\n","    # Full mode\n","    params = {'task_path': DATA_DIR, 'usepytorch': True, 'kfold': 10}\n","    params['classifier'] = {'nhid': 0, 'optim': 'adam', 'batch_size': 64,\n","                                      'tenacity': 5, 'epoch_size': 4}\n","else:\n","    raise NotImplementedError"],"metadata":{"id":"-Air6bXICVId"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# SentEval prepare and batcher\n","def prepare(params, samples):\n","    return"],"metadata":{"id":"GzU4Sm1JCVKm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def batcher(params, batch, max_length=None):\n","    # Handle rare token encoding issues in the dataset\n","    if len(batch) >= 1 and len(batch[0]) >= 1 and isinstance(batch[0][0], bytes):\n","        batch = [[word.decode('utf-8') for word in s] for s in batch]\n","\n","    sentences = [' '.join(s) for s in batch]\n","\n","    # Tokenization\n","    if max_length is not None:\n","        batch = tokenizer.batch_encode_plus(\n","            sentences,\n","            return_tensors='pt',\n","            padding=True,\n","            max_length=max_length,\n","            truncation=True\n","        )\n","    else:\n","        batch = tokenizer.batch_encode_plus(\n","            sentences,\n","            return_tensors='pt',\n","            padding=True,\n","        )\n","\n","    # Move to the correct device\n","    for k in batch:\n","        batch[k] = batch[k].to(device)\n","    \n","    # Get raw embeddings\n","    with torch.no_grad():\n","        outputs = model(**batch, output_hidden_states=True, return_dict=True, sent_emb=True)\n","        pooler_output = outputs.pooler_output\n","        return pooler_output.cpu()\n","\n","    # # Apply different poolers\n","    # if args.pooler == 'cls':\n","    #     # There is a linear+activation layer after CLS representation\n","    #     return pooler_output.cpu()\n","    # elif args.pooler == 'cls_before_pooler':\n","    #     return last_hidden[:, 0].cpu()\n","    # elif args.pooler == \"avg\":\n","    #     return ((last_hidden * batch['attention_mask'].unsqueeze(-1)).sum(1) / batch['attention_mask'].sum(-1).unsqueeze(-1)).cpu()\n","    # elif args.pooler == \"avg_first_last\":\n","    #     first_hidden = hidden_states[0]\n","    #     last_hidden = hidden_states[-1]\n","    #     pooled_result = ((first_hidden + last_hidden) / 2.0 * batch['attention_mask'].unsqueeze(-1)).sum(1) / batch['attention_mask'].sum(-1).unsqueeze(-1)\n","    #     return pooled_result.cpu()\n","    # elif args.pooler == \"avg_top2\":\n","    #     second_last_hidden = hidden_states[-2]\n","    #     last_hidden = hidden_states[-1]\n","    #     pooled_result = ((last_hidden + second_last_hidden) / 2.0 * batch['attention_mask'].unsqueeze(-1)).sum(1) / batch['attention_mask'].sum(-1).unsqueeze(-1)\n","    #     return pooled_result.cpu()\n","    # else:\n","    #     raise NotImplementedError"],"metadata":{"id":"aKpJEeZGCVNW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["VAL_SEPARATOR='|' # '\\t'"],"metadata":{"id":"OXjvhYS46o7Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class PatentFineTuneEval(object):\n","    def __init__(self, task_path, seed=1111):\n","        logging.debug('***** Transfer task : PatentFineTuneEval*****\\n\\n')\n","        self.seed = seed\n","\n","        train = self.loadFile(os.path.join(task_path, 'patent_train.csv'))\n","        #dev = self.loadFile(os.path.join(task_path, 'patent_val.csv'))\n","        test = self.loadFile(os.path.join(task_path, 'patent_test.csv'))\n","\n","        #self.sick_data = {'train': train, 'dev': dev, 'test': test}\n","        self.sick_data = {'train': train, 'test': test}\n","\n","    def do_prepare(self, params, prepare):\n","        samples = self.sick_data['train']['X_A'] + self.sick_data['train']['X_B'] + \\\n","                  self.sick_data['test']['X_A'] + self.sick_data['test']['X_B']\n","        return prepare(params, samples)\n","\n","    def loadFile(self, fpath):\n","        skipFirstLine = True\n","        sick_data = {'X_A': [], 'X_B': [], 'y': []}\n","        with io.open(fpath, 'r', encoding='utf-8') as f:\n","            for line in f:\n","                if skipFirstLine:\n","                    skipFirstLine = False\n","                else:\n","                    text = line.strip().split(VAL_SEPARATOR)\n","                    sick_data['X_A'].append(text[6].split())\n","                    sick_data['X_B'].append(text[7].split())\n","                    sick_data['y'].append(text[5])\n","\n","        sick_data['y'] = [float(s) for s in sick_data['y']]\n","        return sick_data\n","\n","    def run(self, params, batcher):\n","        #sick_embed = {'train': {}, 'dev': {}, 'test': {}}\n","        sick_embed = {'train': {}, 'test': {}}\n","        bsize = params.batch_size\n","\n","        for key in self.sick_data:\n","            logging.info('Computing embedding for {0}'.format(key))\n","            # Sort to reduce padding\n","            sorted_corpus = sorted(zip(self.sick_data[key]['X_A'],\n","                                       self.sick_data[key]['X_B'],\n","                                       self.sick_data[key]['y']),\n","                                   key=lambda z: (len(z[0]), len(z[1]), z[2]))\n","\n","            self.sick_data[key]['X_A'] = [x for (x, y, z) in sorted_corpus]\n","            self.sick_data[key]['X_B'] = [y for (x, y, z) in sorted_corpus]\n","            self.sick_data[key]['y'] = [z for (x, y, z) in sorted_corpus]\n","\n","            for txt_type in ['X_A', 'X_B']:\n","                sick_embed[key][txt_type] = []\n","                for ii in range(0, len(self.sick_data[key]['y']), bsize):\n","                    batch = self.sick_data[key][txt_type][ii:ii + bsize]\n","                    embeddings = batcher(params, batch)\n","                    sick_embed[key][txt_type].append(embeddings)\n","                sick_embed[key][txt_type] = np.vstack(sick_embed[key][txt_type])\n","            sick_embed[key]['y'] = np.array(self.sick_data[key]['y'])\n","            logging.info('Computed {0} embeddings'.format(key))\n","\n","        # Train\n","        trainA = sick_embed['train']['X_A']\n","        trainB = sick_embed['train']['X_B']\n","        trainF = np.c_[np.abs(trainA - trainB), trainA * trainB]\n","        trainY = self.encode_labels(self.sick_data['train']['y'])\n","\n","        # Dev\n","        #devA = sick_embed['dev']['X_A']\n","        #devB = sick_embed['dev']['X_B']\n","        #devF = np.c_[np.abs(devA - devB), devA * devB]\n","        #devY = self.encode_labels(self.sick_data['dev']['y'])\n","\n","        # Test\n","        testA = sick_embed['test']['X_A']\n","        testB = sick_embed['test']['X_B']\n","        testF = np.c_[np.abs(testA - testB), testA * testB]\n","        testY = self.encode_labels(self.sick_data['test']['y'])\n","\n","        config = {'seed': self.seed, 'nclasses': 5}\n","        clf = RelatednessPytorch(train={'X': trainF, 'y': trainY},\n","                                 valid={'X': devF, 'y': devY},\n","                                 test={'X': testF, 'y': testY},\n","                                 devscores=self.sick_data['dev']['y'],\n","                                 config=config)\n","\n","        devspr, yhat = clf.run()\n","\n","        pr = pearsonr(yhat, self.sick_data['test']['y'])[0]\n","        sr = spearmanr(yhat, self.sick_data['test']['y'])[0]\n","        pr = 0 if pr != pr else pr\n","        sr = 0 if sr != sr else sr\n","        se = mean_squared_error(yhat, self.sick_data['test']['y'])\n","        logging.debug('Dev : Spearman {0}'.format(devspr))\n","        logging.debug('Test : Pearson {0} Spearman {1} MSE {2} \\\n","                       for Patent Relatedness\\n'.format(pr, sr, se))\n","\n","        return {'devspearman': devspr, 'pearson': pr, 'spearman': sr, 'mse': se,\n","                'yhat': yhat, 'ndev': len(devA), 'ntest': len(testA)}\n","\n","    def encode_labels(self, labels, nclass=5):\n","        \"\"\"\n","        Label encoding from Tree LSTM paper (Tai, Socher, Manning)\n","        \"\"\"\n","        Y = np.zeros((len(labels), nclass)).astype('float32')\n","        for j, y in enumerate(labels):\n","            for i in range(nclass):\n","                if i+1 == np.floor(y) + 1:\n","                    Y[j, i] = y - np.floor(y)\n","                if i+1 == np.floor(y):\n","                    Y[j, i] = np.floor(y) - y + 1\n","        return Y\n","\n"],"metadata":{"id":"cYdH7cUi0DMM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"SwP-AerIFqkQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class PatentEval(STSEval):\n","    def __init__(self, task_path, seed=1111):\n","        logging.debug('\\n\\n***** Transfer task : PatentEval*****\\n\\n')\n","        self.seed = seed\n","        self.samples = []\n","\n","        train = self.loadFile(os.path.join(task_path, 'patent_train.csv'))\n","        #dev = self.loadFile(os.path.join(task_path, 'patent_val.csv'))\n","        test = self.loadFile(os.path.join(task_path, 'patent_test.csv'))\n","\n","        #self.datasets = ['train', 'dev', 'test']\n","        self.datasets = ['train', 'test']\n","        #self.data = {'train': train, 'dev': dev, 'test': test}\n","        self.data = {'train': train, 'test': test}\n","    \n","    def loadFile(self, fpath):\n","        skipFirstLine = True\n","        sick_data = {'X_A': [], 'X_B': [], 'y': []}\n","        with io.open(fpath, 'r', encoding='utf-8') as f:\n","            for line in f:\n","                if skipFirstLine:\n","                    skipFirstLine = False\n","                else:\n","                    text = line.strip().split(VAL_SEPARATOR)\n","                    \n","                    sick_data['X_A'].append(text[sent0_col].split())\n","                    sick_data['X_B'].append(text[sent1_col].split())\n","                    sick_data['y'].append(text[score_col])\n","                    \n","        sick_data['y'] = [float(s) for s in sick_data['y']]\n","        self.samples += sick_data['X_A'] + sick_data[\"X_B\"]\n","        return (sick_data['X_A'], sick_data[\"X_B\"], sick_data['y'])\n"],"metadata":{"id":"Uc-1UI2zFUhi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class SE(object):\n","    def __init__(self, params, batcher, prepare=None):\n","        # parameters\n","        params = utils.dotdict(params)\n","        params.usepytorch = True if 'usepytorch' not in params else params.usepytorch\n","        params.seed = 1111 if 'seed' not in params else params.seed\n","\n","        params.batch_size = 128 if 'batch_size' not in params else params.batch_size\n","        params.nhid = 0 if 'nhid' not in params else params.nhid\n","        params.kfold = 5 if 'kfold' not in params else params.kfold\n","\n","        if 'classifier' not in params or not params['classifier']:\n","            params.classifier = {'nhid': 0}\n","\n","        assert 'nhid' in params.classifier, 'Set number of hidden units in classifier config!!'\n","\n","        self.params = params\n","\n","        # batcher and prepare\n","        self.batcher = batcher\n","        self.prepare = prepare if prepare else lambda x, y: None\n","\n","        self.list_tasks = [ 'PatentEval', 'CR', 'MR', 'MPQA', 'SUBJ', 'SST2', 'SST5', 'TREC', 'MRPC',\n","                           'SICKRelatedness', 'SICKEntailment', 'STSBenchmark',\n","                           'SNLI', 'ImageCaptionRetrieval', 'STS12', 'STS13',\n","                           'STS14', 'STS15', 'STS16',\n","                           'Length', 'WordContent', 'Depth', 'TopConstituents',\n","                           'BigramShift', 'Tense', 'SubjNumber', 'ObjNumber',\n","                           'OddManOut', 'CoordinationInversion', 'SICKRelatedness-finetune', 'STSBenchmark-finetune', 'STSBenchmark-fix']\n","\n","    def eval(self, name):\n","        # evaluate on evaluation [name], either takes string or list of strings\n","        if (isinstance(name, list)):\n","            self.results = {x: self.eval(x) for x in name}\n","            return self.results\n","\n","        tpath = self.params.task_path\n","        assert name in self.list_tasks, str(name) + ' not in ' + str(self.list_tasks)\n","\n","        # Original SentEval tasks\n","        if name == 'PatentEval':\n","            self.evaluation = PatentEval(tpath , seed=self.params.seed)\n","        elif name == 'CR':\n","            self.evaluation = CREval(tpath + '/downstream/CR', seed=self.params.seed)\n","        elif name == 'MR':\n","            self.evaluation = MREval(tpath + '/downstream/MR', seed=self.params.seed)\n","        elif name == 'MPQA':\n","            self.evaluation = MPQAEval(tpath + '/downstream/MPQA', seed=self.params.seed)\n","        elif name == 'SUBJ':\n","            self.evaluation = SUBJEval(tpath + '/downstream/SUBJ', seed=self.params.seed)\n","        elif name == 'SST2':\n","            self.evaluation = SSTEval(tpath + '/downstream/SST/binary', nclasses=2, seed=self.params.seed)\n","        elif name == 'SST5':\n","            self.evaluation = SSTEval(tpath + '/downstream/SST/fine', nclasses=5, seed=self.params.seed)\n","        elif name == 'TREC':\n","            self.evaluation = TRECEval(tpath + '/downstream/TREC', seed=self.params.seed)\n","        elif name == 'MRPC':\n","            self.evaluation = MRPCEval(tpath + '/downstream/MRPC', seed=self.params.seed)\n","        elif name == 'SICKRelatedness':\n","            self.evaluation = SICKRelatednessEval(tpath + '/downstream/SICK', seed=self.params.seed)\n","        elif name == 'STSBenchmark':\n","            self.evaluation = STSBenchmarkEval(tpath + '/downstream/STS/STSBenchmark', seed=self.params.seed)\n","        elif name == 'STSBenchmark-fix':\n","            self.evaluation = STSBenchmarkEval(tpath + '/downstream/STS/STSBenchmark-fix', seed=self.params.seed)\n","        elif name == 'STSBenchmark-finetune':\n","            self.evaluation = STSBenchmarkFinetune(tpath + '/downstream/STS/STSBenchmark', seed=self.params.seed)\n","        elif name == 'SICKRelatedness-finetune':\n","            self.evaluation = SICKEval(tpath + '/downstream/SICK', seed=self.params.seed)\n","        elif name == 'SICKEntailment':\n","            self.evaluation = SICKEntailmentEval(tpath + '/downstream/SICK', seed=self.params.seed)\n","        elif name == 'SNLI':\n","            self.evaluation = SNLIEval(tpath + '/downstream/SNLI', seed=self.params.seed)\n","        elif name in ['STS12', 'STS13', 'STS14', 'STS15', 'STS16']:\n","            fpath = name + '-en-test'\n","            self.evaluation = eval(name + 'Eval')(tpath + '/downstream/STS/' + fpath, seed=self.params.seed)\n","        elif name == 'ImageCaptionRetrieval':\n","            self.evaluation = ImageCaptionRetrievalEval(tpath + '/downstream/COCO', seed=self.params.seed)\n","\n","        # Probing Tasks\n","        elif name == 'Length':\n","                self.evaluation = LengthEval(tpath + '/probing', seed=self.params.seed)\n","        elif name == 'WordContent':\n","                self.evaluation = WordContentEval(tpath + '/probing', seed=self.params.seed)\n","        elif name == 'Depth':\n","                self.evaluation = DepthEval(tpath + '/probing', seed=self.params.seed)\n","        elif name == 'TopConstituents':\n","                self.evaluation = TopConstituentsEval(tpath + '/probing', seed=self.params.seed)\n","        elif name == 'BigramShift':\n","                self.evaluation = BigramShiftEval(tpath + '/probing', seed=self.params.seed)\n","        elif name == 'Tense':\n","                self.evaluation = TenseEval(tpath + '/probing', seed=self.params.seed)\n","        elif name == 'SubjNumber':\n","                self.evaluation = SubjNumberEval(tpath + '/probing', seed=self.params.seed)\n","        elif name == 'ObjNumber':\n","                self.evaluation = ObjNumberEval(tpath + '/probing', seed=self.params.seed)\n","        elif name == 'OddManOut':\n","                self.evaluation = OddManOutEval(tpath + '/probing', seed=self.params.seed)\n","        elif name == 'CoordinationInversion':\n","                self.evaluation = CoordinationInversionEval(tpath + '/probing', seed=self.params.seed)\n","\n","        self.params.current_task = name\n","        self.evaluation.do_prepare(self.params, self.prepare)\n","\n","        self.results = self.evaluation.run(self.params, self.batcher)\n","\n","        return self.results"],"metadata":{"id":"PDKX78nzzkou"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results = {}"],"metadata":{"id":"otbptLNhCVbk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for task in args.tasks:\n","    se = SE(params, batcher, prepare)\n","    result = se.eval(task)\n","    results[task] = result"],"metadata":{"id":"XdBrj5M0CVeN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Print evaluation results\n","if args.mode == 'dev':\n","    print(\"------ %s ------\" % (args.mode))\n","\n","    task_names = []\n","    scores = []\n","    for task in ['STSBenchmark', 'SICKRelatedness']:\n","        task_names.append(task)\n","        if task in results:\n","            scores.append(\"%.2f\" % (results[task]['dev']['spearman'][0] * 100))\n","        else:\n","            scores.append(\"0.00\")\n","    print_table(task_names, scores)\n","\n","    task_names = []\n","    scores = []\n","    for task in ['MR', 'CR', 'SUBJ', 'MPQA', 'SST2', 'TREC', 'MRPC']:\n","        task_names.append(task)\n","        if task in results:\n","            scores.append(\"%.2f\" % (results[task]['devacc']))    \n","        else:\n","            scores.append(\"0.00\")\n","    task_names.append(\"Avg.\")\n","    scores.append(\"%.2f\" % (sum([float(score) for score in scores]) / len(scores)))\n","    print_table(task_names, scores)\n","\n","elif args.mode == 'test' or args.mode == 'fasttest':\n","    print(\"------ %s ------\" % (args.mode))\n","\n","    task_names = []\n","    scores = []\n","    for task in ['PatentEval', 'STS12', 'STS13', 'STS14', 'STS15', 'STS16', 'STSBenchmark', 'SICKRelatedness']:\n","        task_names.append(task)\n","        if task in results:\n","            if task in ['PatentEval','STS12', 'STS13', 'STS14', 'STS15', 'STS16']:\n","                scores.append(\"%.2f\" % (results[task]['all']['spearman']['all'] * 100))\n","            else:\n","                scores.append(\"%.2f\" % (results[task]['test']['spearman'].correlation * 100))\n","        else:\n","            scores.append(\"0.00\")\n","    task_names.append(\"Avg.\")\n","    scores.append(\"%.2f\" % (sum([float(score) for score in scores]) / len(scores)))\n","    print_table(task_names, scores)\n","\n","    task_names = []\n","    scores = []\n","    for task in ['MR', 'CR', 'SUBJ', 'MPQA', 'SST2', 'TREC', 'MRPC']:\n","        task_names.append(task)\n","        if task in results:\n","            scores.append(\"%.2f\" % (results[task]['acc']))    \n","        else:\n","            scores.append(\"0.00\")\n","    task_names.append(\"Avg.\")\n","    scores.append(\"%.2f\" % (sum([float(score) for score in scores]) / len(scores)))\n","    print_table(task_names, scores)"],"metadata":{"id":"Ye_D2EGrCVgp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qTf6nn0hCVjj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Y2WJdol1CVnn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"yTt7wVkL-SHz"},"execution_count":null,"outputs":[]}]}